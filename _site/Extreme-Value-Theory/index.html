<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Extreme Value Theory: Why Maxima Have Universal Statistics</title>

  <!-- Tag styling -->
  <style>
    .tags { margin: 0.5em 0 1.5em 0; }
    .tag {
      display: inline-block;
      padding: 2px 8px;
      margin: 2px;
      background: rgba(255,255,255,0.08);
      border-radius: 3px;
      font-size: 0.85em;
      text-decoration: none;
      color: var(--muted);
    }
    .tag:hover { background: rgba(255,255,255,0.15); color: var(--accent); }
  </style>

  <!-- MathJax configuration for LaTeX rendering -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        ignoreHtmlClass: "tex2jax_ignore",
        processHtmlClass: "tex2jax_process"
      },
      svg: {
        fontCache: 'global'
      },
      startup: {
        pageReady: function () {
          return MathJax.startup.defaultPageReady().then(function () {
            console.log('MathJax is loaded and ready');
          });
        }
      }
    };
  </script>
  <script type="text/javascript" async src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-svg.js"></script>

  <!-- Site stylesheet -->
  <link rel="stylesheet" href="/crw-blog/assets/css/style.css">
</head>

<body>
  <!-- Header and site title -->
  <header>
    <h1>Fruit of Preterition</h1>
    <nav>
      <ul>
        <li><a href="/crw-blog/">Home</a></li>
        <li><a href="/crw-blog/seeds/">Seeds <span class="wip-badge">WIP</span></a></li>
        <li><a href="/crw-blog/tags/">Tags <span class="wip-badge">WIP</span></a></li>
        <li><a href="/crw-blog/reading/">Reading <span class="wip-badge">WIP</span></a></li>
        <li><a href="/crw-blog/nulla-dies/">Nulla Dies</a></li>
      </ul>
    </nav>
  </header>

  <!-- Main content of the page -->
  <main>
    <div class="site-container">
      <div class="content">
        
        <div class="tags">
          
          <a href="/crw-blog/tags/#seed" class="tag">seed</a>
          
          <a href="/crw-blog/tags/#math" class="tag">math</a>
          
          <a href="/crw-blog/tags/#physics" class="tag">physics</a>
          
        </div>
        
        <h1 id="extreme-value-theory-why-maxima-have-universal-statistics">Extreme Value Theory: Why Maxima Have Universal Statistics</h1>

<h2 id="the-punchline">The Punchline</h2>

<p>The Central Limit Theorem says: sums of random variables converge to Gaussians (under mild conditions).</p>

<p>Extreme Value Theory says: <strong>maxima of random variables converge to one of three distributions</strong> (under mild conditions).</p>

<p>Just three. That’s it. No matter what distribution you start with, the maximum of $N$ samples, properly rescaled, converges to either:</p>
<ul>
  <li><strong>Gumbel</strong> (Type I): light tails (Gaussian, exponential)</li>
  <li><strong>Fréchet</strong> (Type II): heavy tails (power law, Pareto)</li>
  <li><strong>Weibull</strong> (Type III): bounded support (uniform, beta)</li>
</ul>

<p>This is the <strong>Fisher-Tippett-Gnedenko theorem</strong>, and it’s as fundamental as the CLT.</p>

<h2 id="setup-what-were-computing">Setup: What We’re Computing</h2>

<p>Let $X_1, \ldots, X_N$ be iid from some distribution $F(x) = P(X \leq x)$.</p>

<p>Define $M_N = \max(X_1, \ldots, X_N)$.</p>

<p>We have:</p>

\[P(M_N \leq x) = P(X_1 \leq x, \ldots, X_N \leq x) = F(x)^N\]

<p>As $N \to \infty$, this converges to 0 or 1 for any fixed $x$ (unless $x$ is exactly the upper endpoint of the support). We need to <strong>rescale</strong>.</p>

<p>Look for sequences $a_N &gt; 0$, $b_N$ such that:</p>

\[P\left(\frac{M_N - b_N}{a_N} \leq x\right) \to G(x)\]

<p>for some non-degenerate $G$.</p>

<h2 id="the-three-universal-distributions">The Three Universal Distributions</h2>

<h3 id="gumbel-type-i">Gumbel (Type I)</h3>

\[G_1(x) = \exp(-e^{-x}), \quad x \in \mathbb{R}\]

<p>PDF: $g_1(x) = e^{-x} \exp(-e^{-x})$</p>

<p><strong>Domain of attraction:</strong> Distributions with tails decaying faster than any power law but slower than bounded.</p>

<p>Examples: Gaussian, exponential, gamma, lognormal.</p>

<p><strong>Characteristic:</strong> The tail $\bar{F}(x) = 1 - F(x)$ satisfies</p>

\[\lim_{x \to x^*} \frac{\bar{F}(x + t \cdot a(x))}{\bar{F}(x)} = e^{-t}\]

<p>for some auxiliary function $a(x)$.</p>

<h3 id="fréchet-type-ii">Fréchet (Type II)</h3>

\[G_2(x; \alpha) = \begin{cases} 0 &amp; x \leq 0 \\ \exp(-x^{-\alpha}) &amp; x &gt; 0 \end{cases}\]

<p><strong>Domain of attraction:</strong> Power-law tails, $\bar{F}(x) \sim x^{-\alpha}$.</p>

<p>Examples: Pareto, Cauchy, Student-t.</p>

<p><strong>Characteristic:</strong> Regularly varying tails:</p>

\[\lim_{t \to \infty} \frac{\bar{F}(tx)}{\bar{F}(t)} = x^{-\alpha}\]

<h3 id="weibull-type-iii">Weibull (Type III)</h3>

\[G_3(x; \alpha) = \begin{cases} \exp(-(-x)^\alpha) &amp; x \leq 0 \\ 1 &amp; x &gt; 0 \end{cases}\]

<p><strong>Domain of attraction:</strong> Distributions with finite upper endpoint $x^*$.</p>

<p>Examples: Uniform, beta, any bounded distribution.</p>

<p><strong>Characteristic:</strong> Near the endpoint, $\bar{F}(x^* - \epsilon) \sim \epsilon^\alpha$.</p>

<h2 id="the-generalized-extreme-value-distribution">The Generalized Extreme Value Distribution</h2>

<p>All three can be unified into a single family with shape parameter $\xi$:</p>

\[\boxed{G_\xi(x) = \exp\left(-(1 + \xi x)^{-1/\xi}\right)}\]

<p>where $1 + \xi x &gt; 0$.</p>

<ul>
  <li>$\xi &gt; 0$: Fréchet (heavy tail)</li>
  <li>$\xi = 0$: Gumbel (limit as $\xi \to 0$)</li>
  <li>$\xi &lt; 0$: Weibull (bounded)</li>
</ul>

<p>The parameter $\xi$ is the <strong>tail index</strong>. It controls how extreme the extremes get.</p>

<h2 id="why-only-three-the-rg-perspective">Why Only Three? The RG Perspective</h2>

<p>Here’s the physics intuition: <strong>extreme value distributions are RG fixed points</strong>.</p>

<p>Consider the “renormalization” operation: take $N$ samples, compute the max. Then take $N$ of <em>those</em> maxima, compute the max again. This is equivalent to taking the max of $N^2$ original samples.</p>

<p>For the distribution of maxima to be stable under this operation, we need:</p>

\[G(x)^N = G(a_N x + b_N)\]

<p>This is a <strong>functional equation</strong> for $G$, and it turns out to have exactly three solutions (up to location-scale).</p>

<h3 id="the-stability-argument">The Stability Argument</h3>

<p>Let $G$ be an extreme value distribution. Then:</p>

\[G^n(a_n x + b_n) = G(x)\]

<p>for appropriate normalizing sequences.</p>

<p>Taking logs:</p>

\[n \log G(a_n x + b_n) = \log G(x)\]

<p>For this to hold for all $n$, the function $\log(-\log G(x))$ must transform linearly under rescaling. This means:</p>

\[-\log G(x) = c \cdot h(x)\]

<p>where $h$ satisfies the functional equation:</p>

\[h(a_n x + b_n) = \frac{1}{n} h(x)\]

<p>The solutions are:</p>
<ul>
  <li>$h(x) = e^{-x}$ (Gumbel)</li>
  <li>$h(x) = x^{-\alpha}$ for $x &gt; 0$ (Fréchet)</li>
  <li>$h(x) = (-x)^\alpha$ for $x &lt; 0$ (Weibull)</li>
</ul>

<h3 id="von-mises-conditions">Von Mises Conditions</h3>

<p>More explicitly, the <strong>von Mises conditions</strong> characterize each domain of attraction in terms of the hazard rate $r(x) = f(x)/\bar{F}(x)$:</p>

<p><strong>Gumbel:</strong> $\lim_{x \to x^*} \frac{d}{dx}\left(\frac{1}{r(x)}\right) = 0$</p>

<p><strong>Fréchet:</strong> $\lim_{x \to \infty} x \cdot r(x) = \alpha$</p>

<p><strong>Weibull:</strong> $\lim_{x \to x^<em>} (x^</em> - x) \cdot r(x) = \alpha$</p>

<p>The hazard rate is doing the work of the beta function in RG—it controls how fast you run out of probability mass in the tail.</p>

<h2 id="connection-to-the-clt">Connection to the CLT</h2>

<p>The CLT is actually a <em>special case</em> of extreme value theory!</p>

<p>Here’s why: the sum $S_N = X_1 + \cdots + X_N$ can be written as:</p>

\[S_N = \max \text{ over all subsets } \{i_1, \ldots, i_k\} \text{ of } X_{i_1} + \cdots + X_{i_k}\]

<p>…okay, that’s cheating. But here’s the real connection:</p>

<p><strong>Poisson representation:</strong> An exponential random variable $E$ satisfies $E = -\log U$ where $U \sim \text{Uniform}(0,1)$.</p>

<p>The sum of $N$ exponentials is (roughly) $\log N + \text{Gumbel}$.</p>

<p>The max of $N$ uniforms is $1 - e^{-\text{Gumbel}/N} \approx 1 - 1/N$.</p>

<p>There’s a deep duality: <strong>sums of exponentials ↔ maxima of uniforms</strong>.</p>

<p>More precisely: if $E_1, \ldots, E_N$ are iid exponentials, then:</p>

\[\frac{E_1 + \cdots + E_N}{E_1 + \cdots + E_{N+1}}, \ldots, \frac{E_1}{E_1 + \cdots + E_{N+1}}\]

<p>are the <strong>order statistics</strong> of $N$ uniforms on $(0,1)$.</p>

<p>This “exponential-uniform” duality underlies both CLT and EVT.</p>

<h2 id="peaks-over-threshold-the-generalized-pareto">Peaks Over Threshold: The Generalized Pareto</h2>

<p>Instead of block maxima, you can study <strong>exceedances over a high threshold</strong> $u$.</p>

<p><strong>Theorem (Pickands-Balkema-de Haan):</strong> For $F$ in the domain of attraction of $G_\xi$, the conditional distribution of $X - u$ given $X &gt; u$ converges to the <strong>Generalized Pareto Distribution</strong>:</p>

\[H_\xi(x) = 1 - \left(1 + \frac{\xi x}{\sigma}\right)^{-1/\xi}\]

<p>for $x &gt; 0$ (and $1 + \xi x/\sigma &gt; 0$).</p>

<ul>
  <li>$\xi &gt; 0$: Pareto (heavy tail)</li>
  <li>$\xi = 0$: Exponential (limit)</li>
  <li>$\xi &lt; 0$: Bounded above</li>
</ul>

<p>The GPD is to EVT what the exponential is to the CLT (the “infinitely divisible” version).</p>

<h2 id="application-return-periods">Application: Return Periods</h2>

<p>In engineering and finance, we ask: “How big is the 100-year flood?” or “What’s the 99.9th percentile loss?”</p>

<p>If $G$ is the extreme value distribution of annual maxima, the <strong>$T$-year return level</strong> $x_T$ satisfies:</p>

\[G(x_T) = 1 - \frac{1}{T}\]

<p>For the GEV:</p>

\[x_T = \mu + \frac{\sigma}{\xi}\left[\left(-\log(1-1/T)\right)^{-\xi} - 1\right]\]

<p>The tail index $\xi$ controls how fast return levels grow with $T$:</p>
<ul>
  <li>$\xi &gt; 0$: $x_T \sim T^\xi$ (polynomial growth—heavy tails are scary)</li>
  <li>$\xi = 0$: $x_T \sim \log T$ (logarithmic)</li>
  <li>$\xi &lt; 0$: $x_T \to \mu - \sigma/\xi$ (bounded)</li>
</ul>

<h2 id="the-extremal-process">The Extremal Process</h2>

<p>Let ${X_i}$ be iid. The <strong>extremal process</strong> tracks the running maximum:</p>

\[M(t) = \max_{i \leq [Nt]} X_i\]

<p>after proper rescaling. As $N \to \infty$, this converges to a <strong>Poisson point process</strong> transformed by the extreme value distribution.</p>

<p>More precisely: the exceedances over high thresholds form a Poisson process with intensity $\nu(dx) = (1 + \xi x)^{-1/\xi - 1} dx$ (on the appropriate scale).</p>

<p>This is the “continuous-time” version of EVT, just like Brownian motion is continuous-time CLT.</p>

<h2 id="tracy-widom-and-beyond">Tracy-Widom and Beyond</h2>

<p>For <em>dependent</em> random variables with specific correlation structures, you get different universality classes.</p>

<p><strong>Tracy-Widom:</strong> The largest eigenvalue of a random matrix (GUE) has fluctuations described by the Tracy-Widom distribution—NOT Gumbel, despite eigenvalues being “maxima” in some sense. The eigenvalue repulsion changes the universality class.</p>

<p><strong>KPZ universality:</strong> Growth processes, directed polymers, etc. have a different extreme value distribution tied to the Tracy-Widom class.</p>

<p>The EVT fixed points (Gumbel/Fréchet/Weibull) assume independence. Correlations can push you to entirely different universality classes.</p>

<h2 id="summary-table">Summary Table</h2>

<table>
  <thead>
    <tr>
      <th>Property</th>
      <th>Gumbel</th>
      <th>Fréchet</th>
      <th>Weibull</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Tail type</td>
      <td>Light</td>
      <td>Heavy (power)</td>
      <td>Bounded</td>
    </tr>
    <tr>
      <td>Support</td>
      <td>$\mathbb{R}$</td>
      <td>$(0, \infty)$</td>
      <td>$(-\infty, 0)$</td>
    </tr>
    <tr>
      <td>$\xi$</td>
      <td>$0$</td>
      <td>$&gt; 0$</td>
      <td>$&lt; 0$</td>
    </tr>
    <tr>
      <td>Examples</td>
      <td>Gaussian, exp</td>
      <td>Pareto, Cauchy</td>
      <td>Uniform, beta</td>
    </tr>
    <tr>
      <td>$T$-year growth</td>
      <td>$\log T$</td>
      <td>$T^\xi$</td>
      <td>bounded</td>
    </tr>
  </tbody>
</table>

<h2 id="what-we-didnt-cover">What We Didn’t Cover</h2>

<ul>
  <li><strong>Multivariate extreme value theory</strong> (copulas, dependence structures)</li>
  <li><strong>Point process methods</strong> (detailed connection to Poisson processes)</li>
  <li><strong>Statistical inference</strong> (how to estimate $\xi$ from data)</li>
  <li><strong>Extremes of Gaussian processes</strong> (Borell-TIS inequality, etc.)</li>
  <li><strong>Records and their statistics</strong></li>
</ul>

<hr />

<p><em>See also: [Random Matrix Theory Tour], [Free Probability].</em></p>

      </div>
    </div>
  </main>

  <!-- Footer with basic info -->
  <footer>
    <p>&copy; 2026 Fruit of Preterition. Powered by <a href="https://pages.github.com/">GitHub
        Pages</a>.</p>
  </footer>
</body>

</html>