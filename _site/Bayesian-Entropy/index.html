<h1 id="thermodynamics-as-approximate-bayesian-inference">Thermodynamics as Approximate Bayesian Inference</h1>

<h2 id="abstract">Abstract</h2>

<p>In this paper, I illustrate that the branches of physics known as thermodynamics and statistical mechanics may be understood in their entirety as a first-order moment-matching approximation to Bayesian inference. This insight is developed by the extension of the approximation to higher orders, along with a demonstration of the asymptotic correctness of this approximation for a large class of problems. We go on to suggest a framework for generalizations of the Gibbs ensemble for use in various state-inference problems. Finally, we discuss the relationship between the thermodynamic entropy and the information-theoretic entropy in this higher-order thermodynamics.</p>

<hr />

<h2 id="recapitulation-of-the-derivation-of-statistical-mechanics-from-the-principle-of-maximum-entropy">Recapitulation of the Derivation of Statistical Mechanics from the Principle of Maximum Entropy</h2>

<p>We consider a physical system, say an ideal adiabatically isolated box full of classical, distinguishable gas molecules. Assuming for now that (somehow) one has certain knowledge of the nature of the degrees of freedom therein, we may perfectly describe the state of the system by specifying a point in the phase-space of $N$ particles, 
\(\Omega = \mathbb{R}^{6N},\)
where $\Omega$ will be our general notation for the set of all microstates of the system under consideration. Suppose now that an observer were to know, initially, nothing of the state of this system; such an observer might express their uncertainty over the state of the system in the form of a probability distribution over the set of all possible microstates, i.e., an element 
\(p_0 \in \Delta \Omega,\)
with $\Delta$ indicating the space of probability distributions over the set corresponding to the symbol on its right.</p>

<p>If the observer is then to make a measurement of some observable of the system—say, by obtaining the value of a function 
\(f : \Omega \rightarrow \mathbb{R}\)
to be equal to $F$ (with $F$ the observed value of the measurement)—then naturally some new probability distribution in $\Delta \Omega$ should be selected which reflects this information (states inconsistent with measuring $F$ should be decreased in probability). The theory of statistical mechanics revolves around incorporating such information about the system in order to “update” one’s uncertainty probability distribution over the state of the system, on the basis of this new information. (We note up front that here we consider “measurements” which do not impact the state of the system—partly because we wish to elide the distinction between information obtained by measurement and information <em>posited</em> about a system; an adequate theory of quantum measurements in the service of information theory and control may be found in texts on quantum control theory.)</p>

<p>Statistical mechanics typically uses such information about the state to construct a probability distribution on the basis of Gibbs’ “Principle of Maximum Entropy” – prescribing that, given such an observation, one’s updated probability distribution should be that which has the maximum information–entropy while still satisfying the constraint that the expected value of the measurement $f$ over the constructed probability distribution is equal to the observed value $F$. Mathematically, the prescribed $p$ is that which (uniquely, by theorem) solves the following optimization problem:</p>

\[\begin{aligned}
\max_{p \in \Delta \Omega} \quad &amp; -\sum_{\omega \in \Omega} p(\omega) \ln p(\omega)\\
\textrm{s.t.} \quad &amp; \mathbb{E}_{\omega \sim p}[f(\omega)] = F
\end{aligned}\]

<p>The objective function is the <em>information</em> entropy of a probability distribution, which we write as $S_I[p]$.</p>

<p>The solution, proceeding by the method of Lagrange multipliers, gives the family of distributions:</p>

\[\begin{aligned}
p(\omega; \lambda) &amp;= \frac{1}{Z(\lambda)} \exp\Bigl(-\lambda_f\, f(\omega)\Bigr)\\[0.5ex]
Z(\lambda) &amp;= \sum_{\omega \in \Omega} \exp\Bigl(-\lambda_f\, f(\omega)\Bigr)
\end{aligned}\]

<p>For different values of $\lambda_f$, this distribution corresponds to a solution for different observed values $F$. The solution to the problem is that $\lambda_f$ which causes $f$ to take the expectation value $F$; we denote this choice by $\lambda^*_f(F)$. In some cases, it is profitable to consider the Lagrange multiplier to be the independent value whose specification in turn determines a corresponding value for $F$; we say $\lambda_f$ and $F$ (not $f$ the function) are “conjugate.”</p>

<p>Applying this principle to the energy of some system—where $f$ is the total energy $E(\omega)$ of the microstate and its conjugate $\lambda_E$ is the inverse temperature—yields the Gibbs distribution for the microcanonical ensemble:</p>

\[p(\omega) = \frac{1}{Z}\exp\Bigl(-\lambda_E\, E(\omega)\Bigr)\]

<p>Here, the parameter $\lambda_E$ is the inverse temperature of the system; indeed, taking this to be the <em>definition</em> of temperature is appealing. We note that temperature is (1) not a property of the <em>physical</em> system, but instead a parameter describing our probability distribution over it, and (2) not all such probability distributions may be described by a temperature—for example, any system whose exact microstate is known (if this state is not a ground state) is, naively, indescribable in this way.</p>

<p>Now we seek to connect this formulation with Bayesian probability theory.</p>

<hr />

<h3 id="incorporating-prior-distributions">Incorporating Prior Distributions</h3>

<p>If we wish to consider a prior probability distribution $p_0$ and use a slightly modified version of the Principle of Maximum Entropy (PME) to construct the updated distribution by maximizing the <em>relative</em> entropy of the new distribution with respect to the old, we have</p>

\[\begin{aligned}
\max_{p \in \Delta \Omega} \quad &amp; -\sum_{\omega \in \Omega} p(\omega) \ln \frac{p(\omega)}{p_0(\omega)}\\
\textrm{s.t.} \quad &amp; \mathbb{E}_{\omega \sim p}[f(\omega)] = F
\end{aligned}\]

<p>This yields</p>

\[p_{\mathrm{PME}}(\omega | F) = \frac{p_0(\omega)}{Z_f}\exp\Bigl(-\lambda_f\, f(\omega)\Bigr)\]

<p>It may be verified that this update rule is consistent (updating on one observation and then updating on a second is equivalent to updating on both at once). In fact, this update procedure is a useful generalization of Bayes’ rule to allow for more general types of constraints; for details see <a href="#">Geometric Rationality Updating Garrabrant</a>. Further, note that the objective function with the prior corresponds to
\(-D_{KL}(p\parallel p_0) = H(p) - H(p,p_0)\)
(i.e., to minimizing the relative entropy of the posterior from the prior, or equivalently maximizing the difference between the distribution’s entropy and its cross-entropy with the prior).</p>

<p>For the remainder of this work, we shall refer to the “principle of maximum entropy with expectation constraints” (PMEEC)—that is, the principle of maximum entropy <em>as it is generally employed in classical thermodynamics</em>, with constraints only on observables’ <em>expectations</em>.</p>

<hr />

<h2 id="pme-updating-is-non-bayesian">PME Updating Is Non-Bayesian</h2>

<p>Bayes’ rule for updating a probability distribution $p(\omega)$ upon observing $F$ may be written as</p>

\[p(\omega | F) = \frac{p(F | \omega)\,p(\omega)}{p(F)}\]

<p>However, supposing we perform a measurement of the system, it is conceptually incorrect to update on that measurement yielding the given value $F$ <em>in expectation</em>. For example, if one observes that the sky is blue, it would be foolish merely to <em>decrease</em> your estimated probability that it is in fact green—the probability should go all the way to zero (ignoring any possibility of misperception).</p>

<p>If one observes that the observable $f(\omega)$ takes a particular value $F$, states for which $f(\omega) \neq F$ must be updated to probability zero, while states which yield the requisite measurement have their probabilities increased uniformly (in proportion to their prior weight).</p>

<p>The distribution constructed from the PME with expectation constraints (hereafter “Gibbs distributions” constructed with respect to a particular set of measurements) does not fully incorporate the information from the observation.</p>

<p>Of course, classical thermodynamics has achieved enormous practical success in the prediction of physical phenomena; in what follows, we will show that classical thermodynamics is, in a certain sense, a first-order approximation to Bayesian updating. We will then develop this approximation for higher orders in a physical context.</p>

<hr />

<h3 id="the-principle-of-maximum-entropy-with-expectation-constraints-is-the-first-order-moment-matching-approximation-to-bayesian-inference">The Principle of Maximum Entropy with Expectation Constraints Is the First-Order Moment-Matching Approximation to Bayesian Inference</h3>

<p>For ease of comparison, we may write the PMEEC and the correct Bayesian distribution as solutions of the following optimization problems:</p>

\[\begin{aligned}
\text{PMEEC:} \quad
&amp; \max_{p \in \Delta \Omega} \quad -D_{KL}(p \parallel p_0)\\[0.5ex]
&amp; \textrm{s.t.} \quad \mathbb{E}_{\omega \sim p}[f(\omega)] = F\\[2ex]
\end{aligned}
\qquad
\begin{aligned}
\text{Bayes:} \quad
&amp; \max_{p \in \Delta \Omega} \quad -D_{KL}(p \parallel p_0)\\[0.5ex]
&amp; \textrm{s.t.} \quad p(f(\omega)=F) = 1
\end{aligned}\]

<p>We see that PMEEC corresponds to a similar update procedure as the Bayesian update, except that only the first moment of the induced distribution $p(f(\omega))$ is constrained, rather than the entire distribution.</p>

<p>In fact, requiring the observation to occur with probability one is equivalent to requiring the induced distribution to be a delta function, which in turn implies that the $n$th moment equals the first moment raised to the $n$th power:</p>

\[p(f(\omega)=F) \propto \delta \Bigl(f(\omega) - F\Bigr)
\quad\leftrightarrow\quad
\mathbb{E}[f^n] = \bigl(\mathbb{E}[f]\bigr)^n \quad \forall\, n\in \mathbb{Z}^+\]

<p>(moment-matching is necessary but not sufficient in general to prove the equality of two distributions on an infinite interval.)</p>

<p>It is clear that classical thermodynamics offers great computational facility—and equally clear that this comes at the cost of information loss relative to the correct Bayesian updates (we will later discuss this lost information in the context of the Second Law).</p>

<p>We may construct a hierarchy of “higher-order” thermodynamics corresponding to increasingly strict constraints on the induced-distribution moments. We will call the “$N$th order Gibbs distribution” the solution to the problem</p>

\[\begin{aligned}
\max_{p \in \Delta \Omega} \quad &amp; -D_{KL}(p \parallel p_0)\\[0.5ex]
\textrm{s.t.} \quad &amp; \mathbb{E}_{\omega \sim p}[f^n(\omega)] = F^n \quad \text{for } n=0,\dots,N
\end{aligned}\]

<p>In terms of the traditional Lagrange multipliers, this yields the distribution</p>

\[p_N(\omega | f(\omega)=F) = \frac{1}{Z_N} \exp\Biggl(-\sum_{n=1}^N \lambda_n\, \bigl(f(\omega)\bigr)^n\Biggr)\]

<p>with $Z_N$ the appropriate normalization constant.</p>

<p>As an example, consider a measurement $f$ which takes discrete values $f_i$ for $i=1,\dots,M$ (though the state space need not be discrete). The form of the constraint is given by a Vandermonde matrix whose rank determines the number of moments necessary to achieve the delta function; let $p_i$ correspond to the probability of being in the subspace yielding measurement $f_i$ (with $p_i$ uniformly distributed over all states within that subspace). Then the constraint at order $N$ takes the form</p>

\[\begin{bmatrix} 
f_1 &amp; \dots  &amp; f_M\\[0.5ex]
\vdots &amp; \ddots &amp; \vdots\\[0.5ex]
f_1^N &amp; \dots  &amp; f_M^N 
\end{bmatrix}
\begin{bmatrix} 
p_1\\[0.5ex]
\vdots \\[0.5ex]
p_M 
\end{bmatrix}
=
\begin{bmatrix} 
F^1\\[0.5ex]
\vdots \\[0.5ex]
F^N 
\end{bmatrix}\]

<p>Since (by assumption) the $f_i$ are all distinct, the rank of the Vandermonde matrix is $\min(N,M)$; that is, specifying as many moments as there are distinct measurements suffices to yield the requisite delta-function distribution. Thus, for a discrete observable that can take $M$ distinct values, $M$th order thermodynamics is exactly equivalent to Bayesian updating!</p>

<p>Further, for an observable with a discrete spectrum having infinitely many distinct values, the $N$th order Gibbs distribution will be an approximation to the correct Bayesian update for all finite $N$. We leave to future work the more mathematically delicate question of continuous-spectrum observables.</p>

<hr />

<h2 id="in-defence-of-pmeec">In Defence of PMEEC</h2>

<p>That Bayes’ rule should be the “gold standard” against which any update rule is measured is evidenced by consistency theorems (e.g., von Neumann–Morgenstern or Dutch–Book) and by noting that adherence to Bayes is a defining property of probability distributions.</p>

<h3 id="the-thermodynamic-limit">The Thermodynamic Limit</h3>

<p>Thermodynamics simplifies physics by considering large-$N$ limits. We might ask whether such a limit justifies using the PMEEC instead of the full Bayesian calculation. Suppose we can define the state space $\Omega(N)$ and some observable $E$ that is well defined in the large-$N$ limit. If the error is quantified using the KL divergence, the error will typically be infinite for continuous observables (since the PMEEC will generally assign some probability density over the whole space, whereas the Bayesian distribution must be a delta function on the “true” manifold—almost all of the PMEEC mass will lie in regions where the Bayesian distribution is zero). Assuming the system is discrete, we calculate (with $p_B$ the Bayesian and $p_G$ the Gibbs distribution, using uniform priors for both):</p>

\[D_{KL}(p_{B}\parallel p_{G}) = \beta E_0 + \ln\!\left[\frac{\sum_{\omega} e^{-\beta E(\omega)}}{|E_N^{-1}(E_0)|}\right] = -(F_N-E_0)\beta - \ln|E_N^{-1}(E_0)| = S_G - S_B\]

<p>The final form shows that the divergence is the difference in the two entropies—and since $S_G$ maximizes the entropy subject to a looser constraint than $S_B$, this difference is nonnegative.</p>

<p>As for large-$N$ behavior, the free energy $F_N$ can be broken down into volumetric, surface, etc. terms (i.e., the component of $F$ that converges when divided by $N$, the component that converges when divided by $N^{1-1/d}$, etc.). Thus, we may write an asymptotic series for $F$ approximately as</p>

\[F \sim \sum_{n\leq d} f_n\, N^{1-\frac{n}{d}},\]

<p>(in principle, this series need not terminate, though that would be a pathological case). Different observables $E$ will have inverse images scaling differently with $N$—most observables of interest will be exponential or superexponential in $N$ (perhaps due to combinatorially many ways of arranging a given number of particles in various states), but other behaviors are possible.</p>

<p>This analysis is somewhat an artifact of using the KL divergence. A better analysis might involve calculating the “Earth-Mover Distance,” but lacking a simple method for that here, I offer a hackier criterion: the corrections are plausibly unimportant if the Gibbs distribution converges to the Bayesian distribution blurred by a Gaussian with variance $\epsilon&gt;0$ (i.e., take the $N$ limit for fixed $\epsilon$, and then see if the KL distance goes to zero as $\epsilon$ does):</p>

\[e^{-\beta E + \ln g_N(E)} \rightarrow e^{-\frac{1}{2}\left(\frac{E-E_0}{\epsilon}\right)^2}\]

<p>where $g_N$ is the density of states.</p>

<h3 id="implementing-measurement-noise-need-not-yield-a-gibbs-distribution">Implementing Measurement Noise Need Not Yield a Gibbs Distribution</h3>

<p>Another possible reason to prefer PMEEC over full Bayesian updating is that measurements might be noisy, so a “gentler” update is appropriate. Here we discuss how this works—and how it might not.</p>

<p>We have so far assumed that all measurements of the system are ideal; now, let us relax that assumption to allow for “noisy” measurements. (Note that measurements which are “coarse” in the sense of mapping many possible microstates to a single observed value—for example, the energy of a many-particle system—can be conceptually handled without explicit noise.)</p>

<table>
  <tbody>
    <tr>
      <td>Suppose that a measurement of the observable $f(\omega)$ is drawn according to a probability distribution $p(m_f</td>
      <td>f(\omega))$. Assume for simplicity that the measurement distribution may vary depending on $f$ but not directly on the microstate $\omega$, and that the observed value is $M_f$. The Bayesian update prescription is no different than before; it may be formulated as an (unconstrained) optimization problem:</td>
    </tr>
  </tbody>
</table>

\[\max_{p \in \Delta \Omega} \quad \Bigl\{-D_{KL}(p\parallel p_0) + \mathbb{E}_p\bigl[\ln p(M_f | \omega)\bigr]\Bigr\}\]

<p>That is, the Bayes posterior maximizes the difference between the expected log-likelihood of the measurement and the relative entropy (with respect to the prior).</p>

<table>
  <tbody>
    <tr>
      <td>One might inquire whether there exists a simple measurement–error profile that naturally entails the PMEEC approximation—that is, whether there exists a $p(m</td>
      <td>\omega)$ such that the Bayes posterior given the noisy measurement value equals the Gibbs distribution for the observable measured with no error:</td>
    </tr>
  </tbody>
</table>

\[\frac{e^{-\lambda(m_f) f(\omega)}}{Z(m_f)} = p(\omega | m_f) = \frac{p(m_f|f(\omega))\, p(\omega)}{p(m_f)}\]

<p>Then (assuming, for simplicity, a uniform prior),</p>

\[p(m_f | f(\omega)) = \frac{e^{-\lambda(m_f)[f(\omega) - m_f]}}{\tilde{Z}(m_f)}\]

<p>That is, for fixed $m_f$, the measurement noise is a decaying exponential in the signed distance from $f(\omega)$. The behavior as $m_f$ varies is complex, and it is not clear what to make of it, if anything.</p>

<p>In the moment-matching approximation, we impose the constraint that the induced distribution on $f$ of the new distribution must match the $N$th moment of the Bayesian distribution. The $N$th order approximation is derived from the optimization problem:</p>

\[\begin{aligned}
\max_{p \in \Delta \Omega} \quad &amp; -D_{KL}(p\parallel p_0)\\
\textrm{s.t.} \quad &amp; \mathbb{E}_{\omega \sim p}\Bigl[f(\omega)^n\Bigr] = \int d\omega\, \frac{p(M_f | f(\omega))\, p_0(\omega)}{p_0(M_f)}\, f(\omega)^n \quad \text{for } n=0,\dots,N
\end{aligned}\]

<p>Once the measurement is noisy, the constraining data need no longer be the powers of the mean $F$. For $f$ with a discrete spectrum, the argument above—that only as many moments as there are distinct values of $f$ need to be specified in order to derive the exact Bayes posterior—still holds.</p>

<hr />

<h2 id="example-derivation-of-second-order-maxwellboltzmann-velocity-distribution">Example Derivation of Second-Order Maxwell–Boltzmann Velocity Distribution</h2>

<p>Consider a classical ideal gas as is traditionally used to derive the Maxwell–Boltzmann distribution. We seek the probability distribution function that predicts the energy of each particle:</p>

\[Z = \int \exp\Biggl[ -\sum_{k=0}^N \beta_k\, E^k(\omega) \Biggr]\, d\omega\]

<p>Because the $\beta_k$ are nonnegative (arising from their origin as Lagrange multipliers), the exponent is strictly negative and strictly decreasing. Determining the $\beta_k$ given the required expectation value of $E$ is clearly nontrivial in general; nonetheless, observables may be computed—as in the traditional theory—by examining derivatives of the log-partition function $Z$.</p>

<p>The first problem is that even for an ideal gas (with no interactions), the partition function no longer factorizes into a product of single-particle partition functions—it now incorporates correlations between the particles. (For example, $E^2(\omega) = \Bigl[\sum_i E(\omega_i)\Bigr]^2$ is not linear in the energies of individual particles.) The velocity distribution becomes</p>

\[Z_N(\beta_1,\beta_2) = \int \Biggl(\prod_i d^3\vec{v}_i\Biggr) \exp\Biggl[-\beta_1 \sum_i v_i^2 - \beta_2 \Bigl(\sum_i v_i^2\Bigr)^2 \Biggr] = \frac{S_{3N-1}}{2} \int_0^\infty dX\, X^{\frac{3}{2}N - 1} e^{-\beta_1 X - \beta_2 X^2}\]

<p>where 
\(S_d = \frac{2\pi^{d/2}}{\Gamma(d/2)}\)
is the surface area of a unit sphere in $d$ dimensions, and $N$ is the number of particles.</p>

<hr />

<h2 id="perturbation-theory-and-higher-order-thermodynamics">Perturbation Theory and Higher-Order Thermodynamics</h2>

<p>As noted, the (first-order) Gibbs distribution is remarkable for the facility with which it allows one to calculate expectation values of observables. This fact is often exploited to perform perturbative calculations, reducing observable calculations in the perturbed system to expansions of expectations in the (first-order) equilibrium system.</p>

<p>Higher orders of the moment-matching expansion may be approximated as perturbations of the first-order Gibbs distribution, with the higher moment terms providing the perturbation.</p>

<p>Consider a system modeled by an unperturbed Hamiltonian $H_0(\omega)$ and a perturbing potential $H_I(\omega)$. The associated Gibbs distribution at order $N$ is</p>

\[p(\omega) = \frac{ \exp\Biggl(-\sum_{k=0}^N \beta_k\, \Bigl[H_0(\omega) + H_I(\omega)\Bigr]^k \Biggr)}{\int \exp\Biggl(-\sum_{k=0}^N \beta_k\, \Bigl[H_0(\omega) + H_I(\omega)\Bigr]^k \Biggr) d\omega}\]

<p>Two separate expansions are required—the first with respect to the perturbing potential, and the second with respect to the higher-order moments. Let $O(\omega)$ be an observable; its expectation is</p>

\[\langle O \rangle_{N} = \int d\omega\, O(\omega)\, p(\omega)\]

<p>Here, $\langle \cdot \rangle_{k}$ denotes the expectation with respect to the $k$th order Gibbs distribution (to full order in $H_I$), while we reserve $\langle \cdot \rangle_{k,0}$ to mean the expectation with respect to the <em>unperturbed</em> $k$th order Gibbs distribution (so $\langle \cdot \rangle_{0,0}$ refers to the traditional first-order unperturbed distribution).</p>

<p>We may develop perturbation expansions as follows:</p>

\[\begin{aligned}
\langle O \rangle_{N} &amp;= \frac{\Bigl\langle O\, \exp\Bigl[-\sum_{k=1}^N \beta_k\Bigl((H_0 + H_I)^k - H_0^k\Bigr)\Bigr]\Bigr\rangle_{N,0}}{\Bigl\langle \exp\Bigl[-\sum_{k=1}^N \beta_k\Bigl((H_0 + H_I)^k - H_0^k\Bigr)\Bigr]\Bigr\rangle_{N,0}}\\[1ex]
\langle O \rangle_{N} &amp;= \frac{\Bigl\langle O\, \exp\Bigl[\beta_1 H_0 - \sum_{k=1}^N \beta_k\Bigl((H_0 + H_I)^k\Bigr)\Bigr]\Bigr\rangle_{0,0}}{\Bigl\langle \exp\Bigl[\beta_1 H_0 - \sum_{k=1}^N \beta_k\Bigl((H_0 + H_I)^k\Bigr)\Bigr]\Bigr\rangle_{0,0}}
\end{aligned}\]

<p>The first equation is useful if an analytic or otherwise tractable form of the $N$th order Gibbs distribution is available (e.g., if it is the delta distribution corresponding to an exactly constrained total energy in the absence of interactions), while the second describes the expectation with respect to the traditional first-order Gibbs distribution of thermal equilibrium. Perturbation expansions may then be carried out by Taylor expanding the exponentials; as in traditional field theory, a diagrammatic expansion of the numerator and denominator implies that the answer can be taken as the sum over connected diagrams only.</p>

<hr />

<h2 id="higher-order-gibbs-distributions-are-not-separable">Higher Order Gibbs-Distributions Are Not Separable</h2>

<p>Consider a gas of classical non-interacting particles. We are often interested in “extensive” quantities; let us denote such a quantity by $E(\omega)$, satisfying</p>

\[E(\omega) = \sum_i E(\omega_i)\]

<p>where $i$ indexes the subsystems (or particles) of the system, with a total of $N$ subsystems. The first-order Gibbs distribution is</p>

\[\begin{aligned}
p(\omega_1,\dots,\omega_N) &amp;= \frac{1}{Z}\exp\Bigl[-\sum_i \lambda\, E(\omega_i)\Bigr] \\
&amp;= \prod_i \frac{e^{-\lambda\, E(\omega_i)}}{Z_i} = \prod_i p_i(\omega_i)
\end{aligned}\]

<p>i.e. the probability distribution for each subsystem is <em>independent</em> of the others. The second-order Gibbs distribution is given by</p>

\[p(\omega_1,\dots,\omega_N) = \frac{1}{Z}\exp\Bigl[-\sum_i \lambda_1\, E(\omega_i) - \lambda_2\, \Bigl(\sum_i E(\omega_i)\Bigr)^2\Bigr]\]

<p>It is clear upon inspection that this distribution does not factor into a product of independent distributions—in fact, it introduces a nonlocal “interaction” between each pair of subsystems (which is purely inferential in nature, not physical).</p>

<p>For example, suppose a system consisting of 3 particles is known to have 8 total quanta of energy; if the first two particles have 2 and 4 quanta respectively, then the number of quanta assigned to the third particle cannot be independent of this information!</p>

<p>With this in mind, one might ask if there is a sense in which the first-order Gibbs distribution is optimal—that is, optimal among distributions that factor into independent marginals. Such an optimal distribution would solve</p>

\[\begin{aligned}
\min_{p \in \Delta \Omega} \quad &amp; D_{KL}(p_B \parallel p)\\
\textrm{s.t.} \quad &amp; p(\omega_1,\dots,\omega_N) = p_1(\omega_1) \cdots p_N(\omega_N) \quad \forall\,\omega_1,\dots,\omega_N
\end{aligned}\]

<p>where the equality constraint means that there exist marginal distributions $p_1,\dots,p_N$ and $p_B$ is the correct Bayesian distribution. (The discussion of the marginal distributions is left incomplete here.)</p>

<hr />

<h2 id="the-second-law-and-its-discontents">The Second Law and Its Discontents</h2>

<p>The second law is a cornerstone of modern physics. Grandy provides an enlightening treatment of entropy and possible caveats to the second law, which was one inspiration for the ideas in this paper. Here we offer our own perspective, with additional remarks on Landauer’s limit.</p>

<p>For deterministic classical systems, Bayesian updating on observations does not increase the entropy. Thus, if one defines a time-dependent entropy as the entropy of the probability distribution generated from continuous-time updating (in Grandy’s treatment using the PMEEC—albeit with modifications to discard certain information in order to recover the classical rules of thermodynamics), one obtains a model where measurements taken at discrete times update the probability distribution over the initial microstate.</p>

<p>Specifically, define</p>

\[\begin{aligned}
S_t = \max_{p \in \Delta \Omega} \quad &amp; S_I[p]\\
\textrm{s.t.} \quad &amp; p(O_i(\omega)=o_i) = 1 \quad \text{for } i=0,\dots,t
\end{aligned}\]

<p>for observables $O_i$ measured to have value $o_i$. In this model, $S_t$ is nondecreasing in $t$ and will decrease whenever a measurement places nontrivial constraints on the microstates. This is in contradiction to the empirically valid second law. We now turn to a discussion of Landauer’s limit to understand this divergence.</p>

<p>Landauer’s limit is a hypothetical bound on the amount of heat created during irreversible computation at a given temperature $T$, viz.</p>

\[\Delta Q \geq \beta^{-1} \ln 2\]

<p>The argument is roughly as follows: during computation, a bit register must change state; if this change is irreversible—so that information about the previous state cannot be inferred from the current state—then (by classical determinism) the lost information must be ejected into the environment. This transfer of information increases the entropy of our probability distribution over the environment, corresponding to at least one bit of heat. (If computations are reversible, as in some cases in quantum computing, this limit does not apply. Likewise, if one keeps an updated probability distribution over the environment, the limit may not apply.) Thus, Landauer’s limit is not a fundamental law of nature but an implication of a particular model of how an observer stores and discards data about the environment and system.</p>

<p>To illustrate this, note that in the Landauer example the observer has complete knowledge of the computer system and uses a single parameter (the temperature $\beta$) to describe the probability distribution over the environment. When the state of the computer changes, this information alters the distribution—effectively updating to a new temperature $\beta’$ (assuming some prior knowledge of the environment’s thermal properties implicit in its microstate structure). This represents a “project–evolve–project” motif: the environment’s state is projected onto a manifold of probability distributions parameterized by $\beta$ and then parallel transported along that manifold by the dynamics of the combined system and environment.</p>

<p>Now, consider a generalization where the observer models the system with a vector of parameters $\beta$. Suppose we have $\omega_t = (\omega_{S,t}, \omega_{E,t})$ evolving deterministically. Assume the observer “knows” the microstate $\omega_{S,t}$ and maintains a model of the marginal $p_E(\omega_{E,t}; \beta_t)$, where $\beta_t$ is updated at each time step. The observer is then to “forget” the microstate $\omega_{S,t}$ upon learning the new state $\omega_{S,t+1}$, with a brief overlap where both states are known so that $\beta_t$ can be updated optimally. The new distribution should minimize</p>

\[D_{KL}\Bigl(p(\omega_{E,t+1} |\beta_{t}, \omega_{S,t}) \,\parallel\, p_E(\omega_{E,t+1}; \beta_{t+1})\Bigr)\]

<table>
  <tbody>
    <tr>
      <td>Or one might reference the globally optimal distribution $p(\omega_{E,t+1}</td>
      <td>{\omega_S}_{t’\le t})$. Thus, one seeks</td>
    </tr>
  </tbody>
</table>

\[\min_{\beta_{t+1} } \quad \int d\omega_{E,t+1}\, p(\omega_{E,t+1} | \beta_t, \omega_{S,t}) \ln p(\omega_{E,t+1} | \beta_{t+1})\]

<table>
  <tbody>
    <tr>
      <td>If we define $p(\omega_{E,t+1}</td>
      <td>\beta_t, \omega_{S,t})$ as equal to $p(\omega_{E,t}</td>
      <td>\beta_t)$ if there exists an $\omega_{S,t+1}$ such that $(\omega_{S,t},\omega_{E,t})$ evolves to $ (\omega_{S,t+1},\omega_{E,t+1}) $, and 0 otherwise, then the change in entropy is given by $D_{KL}(\beta_{t+1} \parallel \beta_t)$.</td>
    </tr>
  </tbody>
</table>

<p>In the case where $\beta$ is a complete parameterization of $\Delta \Omega_E$, the entropy is zero and $\beta$ updates solely to reflect time evolution.</p>

<p>Finally, we can discuss the geometric interpretation of the entropy increase: the distributions parameterized by $\beta$ form a submanifold $B$ of $\Delta \Omega$. The entropy $S$ is a scalar function on $\Delta \Omega$, and the system evolves under a Hamiltonian $H$ which induces a Liouville operator $L$ on $\Delta \Omega$. A point $p$ in $\Delta \Omega$ is evolved by $L$ along a path where $S$ is constant (since no information is lost under deterministic, reversible evolution). However, $L$ induces an effective evolution $L_B = P_B L$ on the manifold $B$ (where $P_B$ is the projection operator from the tangent bundle $T\Delta \Omega$ to $TB$); in general, $L_B$ does not move along iso-entropy lines. In other words, the time derivative of the entropy along $L_B$ is</p>

\[\frac{d}{dt} S(\beta) = \nabla_{L_B} S = \mathcal{I}\bigl(P_B \nabla S,\, P_B L\bigr)\]

<p>with $\mathcal{I}$ denoting the Fisher metric (which defines the inner product).</p>

<p>A cute example application is that the accrued entropy may depend on the number of parameters used (one might choose the parameterization optimally). If $T\Delta \Omega$ has $N$ dimensions and $TB$ has $n$, then if $\nabla S$ and $L_B$ are “unrelated” random vectors, the expected entropy generation is roughly one quarter of the trace of the Fisher information.</p>

<hr />

<h2 id="appendix-information-preserving-first-order-thermodynamics">Appendix: Information-Preserving First-Order Thermodynamics</h2>

<p>Grandy develops time-dependent thermodynamics by considering constraints that fix the expected value of an observable $F$ at the time when the time-dependent distribution $\rho_t$ is calculated, namely $\langle F(t) \rangle_t$. This yields</p>

\[\rho_t = \frac{1}{Z_t}\exp\Biggl(-\beta H - \int_0^t \lambda(t')\, F(t')\, dt'\Biggr)\]

<p>At each time $t$, the Lagrange multiplier $\lambda(t)$ is set to fix</p>

\[\langle F(t) \rangle_t = \operatorname{Tr}\Bigl(\rho_t F(t)\Bigr) = - \left[ \frac{\delta}{\delta \lambda(t)} \ln Z_t \right]_{\lambda(t)=\lambda^*(t)}\]

<p>While this method allows one to develop a time-dependent thermodynamics, the procedure is not consistent; although it fixes the expectation values $\langle F(t’)\rangle_{t’}$ at the time of measurement, these values are not constrained at later times—i.e., $\langle F(t’)\rangle_t \neq \langle F(t’)\rangle_{t’}$ even after constraining $F(t’)$ by measurement.</p>

<p>This issue can be remedied within first-order thermodynamics by replacing $\lambda(t’)$ with $\lambda_t(t’)$; then, at each time $t$, the entire set of Lagrange multipliers must be redetermined. One then has</p>

\[\rho_t = \frac{1}{Z_t}\exp\Biggl(-\beta H - \int_0^t \lambda_t(t')\, F(t')\, dt'\Biggr)\]

<p>with the multipliers determined by requiring</p>

\[\langle F(t')\rangle_t = - \left[ \frac{\delta}{\delta \lambda_t(t')}\ln Z_t \right]_{\lambda_t=\lambda^*_t} \quad \forall\, 0\le t'\le t\]

<p>That is, the multipliers are now determined by a <em>functional</em> equation rather than a single nonlinear equation. This adds considerable complexity; moreover, the common short-memory approximation (i.e., that system correlations decay rapidly) suggests that constraining information from far in the past is irrelevant. Nonetheless, in discussions of apparent irreversibilities it is important to acknowledge that such approximations entail the discarding of information.</p>

<p>The entropy of the system is then given by</p>

\[\frac{1}{k} S_t = \ln Z_t - \beta \langle H \rangle_t - \int_0^t \lambda_t(t')\, \langle F(t')\rangle_t \, dt'\]

<p>It may be observed that the time derivative of the density matrix (i.e. the change in the density matrix due solely to changes in the information used to construct it, rather than due to unitary time evolution) satisfies</p>

\[\partial_t \rho_t = \rho_t \Biggl[ \int_0^t \partial_t \lambda_t(t')\, \Bigl(\overline{F(t')} - \langle F(t')\rangle_t\Bigr)\, dt' + \lambda_t(t)\,\Bigl(\overline{F(t)}-\langle F(t)\rangle_t\Bigr) \Biggr]\]

<p>where the overbar denotes the generalized Kubo transform of the operator (taken with respect to $\ln \rho_t$). The time derivative of an operator’s expectation can be written as</p>

\[\frac{d}{dt}\langle C(t)\rangle_t = \langle \dot{C}(t)\rangle_t + \lambda_t(t)\, K_{CF}^t(t,t) + \int_0^t \partial_t \lambda_t(t')\, K_{CF}^t(t',t) \, dt'\]

<p>which in turn leads to the definition of the source $\sigma_C(t)$ (heuristically, the extent to which the expectation of $C$ changes due to the updating of the density matrix):</p>

\[\sigma_C(t) = \frac{d}{dt}\langle C(t)\rangle_t - \langle \dot{C}(t)\rangle_t = \lambda_t(t)\, K_{CF}^t(t,t) + \int_0^t \partial_t \lambda_t(t')\, K_{CF}^t(t',t) \, dt'\]
